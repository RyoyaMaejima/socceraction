{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T14:03:57.161890Z",
     "iopub.status.busy": "2021-09-17T14:03:57.161251Z",
     "iopub.status.idle": "2021-09-17T14:03:57.569373Z",
     "shell.execute_reply": "2021-09-17T14:03:57.569881Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T14:03:57.576046Z",
     "iopub.status.busy": "2021-09-17T14:03:57.575455Z",
     "iopub.status.idle": "2021-09-17T14:03:59.013717Z",
     "shell.execute_reply": "2021-09-17T14:03:59.012690Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import socceraction.atomic.vaep.features as fs\n",
    "import socceraction.atomic.vaep.labels as lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T14:03:59.018594Z",
     "iopub.status.busy": "2021-09-17T14:03:59.017909Z",
     "iopub.status.idle": "2021-09-17T14:03:59.044746Z",
     "shell.execute_reply": "2021-09-17T14:03:59.043693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure file and folder names\n",
    "datafolder = \"../data-fifa\"\n",
    "spadl_h5 = os.path.join(datafolder, \"atomic-spadl-statsbomb.h5\")\n",
    "features_h5 = os.path.join(datafolder, \"atomic-features.h5\")\n",
    "labels_h5 = os.path.join(datafolder, \"atomic-labels.h5\")\n",
    "predictions_h5 = os.path.join(datafolder, \"atomic-predictions-one-action.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T14:03:59.048926Z",
     "iopub.status.busy": "2021-09-17T14:03:59.048313Z",
     "iopub.status.idle": "2021-09-17T14:03:59.199796Z",
     "shell.execute_reply": "2021-09-17T14:03:59.200393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of games: 64\n"
     ]
    }
   ],
   "source": [
    "games = pd.read_hdf(spadl_h5, \"games\")\n",
    "print(\"nb of games:\", len(games))\n",
    "\n",
    "# note: only for the purpose of this example and due to the small dataset,\n",
    "# we use the same data for training and evaluation\n",
    "traingames = games\n",
    "testgames = games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T14:03:59.212791Z",
     "iopub.status.busy": "2021-09-17T14:03:59.211994Z",
     "iopub.status.idle": "2021-09-17T14:04:00.961702Z",
     "shell.execute_reply": "2021-09-17T14:04:00.960823Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting features: 100%|██████████| 64/64 [00:00<00:00, 73.44it/s]\n",
      "Selecting label: 100%|██████████| 64/64 [00:00<00:00, 94.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: ['type_pass_a0', 'type_cross_a0', 'type_throw_in_a0', 'type_freekick_crossed_a0', 'type_freekick_short_a0', 'type_corner_crossed_a0', 'type_corner_short_a0', 'type_take_on_a0', 'type_foul_a0', 'type_tackle_a0', 'type_interception_a0', 'type_shot_a0', 'type_shot_penalty_a0', 'type_shot_freekick_a0', 'type_keeper_save_a0', 'type_keeper_claim_a0', 'type_keeper_punch_a0', 'type_keeper_pick_up_a0', 'type_clearance_a0', 'type_bad_touch_a0', 'type_non_action_a0', 'type_dribble_a0', 'type_goalkick_a0', 'type_receival_a0', 'type_out_a0', 'type_offside_a0', 'type_goal_a0', 'type_owngoal_a0', 'type_yellow_card_a0', 'type_red_card_a0', 'type_corner_a0', 'type_freekick_a0', 'bodypart_foot_a0', 'bodypart_head_a0', 'bodypart_other_a0', 'bodypart_head/other_a0', 'goalscore_team', 'goalscore_opponent', 'goalscore_diff', 'x_a0', 'y_a0', 'dist_to_goal_a0', 'angle_to_goal_a0', 'dx_a0', 'dy_a0', 'period_id_a0', 'time_seconds_a0', 'time_seconds_overall_a0']\n",
      "Y: ['scores', 'concedes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Select feature set X\n",
    "xfns = [\n",
    "    #fs.actiontype,\n",
    "    fs.actiontype_onehot,\n",
    "    #fs.bodypart,\n",
    "    fs.bodypart_onehot,\n",
    "    fs.goalscore,\n",
    "    fs.location,\n",
    "    fs.polar,\n",
    "    fs.direction,\n",
    "    fs.team,\n",
    "    fs.time,\n",
    "    fs.time_delta\n",
    "]\n",
    "nb_prev_actions = 1\n",
    "\n",
    "Xcols = fs.feature_column_names(xfns, nb_prev_actions)\n",
    "\n",
    "def getXY(games, Xcols):\n",
    "    # generate the columns of the selected feature\n",
    "    X = []\n",
    "    for game_id in tqdm.tqdm(games.game_id, desc=\"Selecting features\"):\n",
    "        Xi = pd.read_hdf(features_h5, f\"game_{game_id}\")\n",
    "        X.append(Xi[Xcols])\n",
    "    X = pd.concat(X).reset_index(drop=True)\n",
    "\n",
    "    # 2. Select label Y\n",
    "    Ycols = [\"scores\", \"concedes\"]\n",
    "    Y = []\n",
    "    for game_id in tqdm.tqdm(games.game_id, desc=\"Selecting label\"):\n",
    "        Yi = pd.read_hdf(labels_h5, f\"game_{game_id}\")\n",
    "        Y.append(Yi[Ycols])\n",
    "    Y = pd.concat(Y).reset_index(drop=True)\n",
    "    return X, Y\n",
    "\n",
    "X,Y = getXY(traingames, Xcols)\n",
    "print(\"X:\", list(X.columns))\n",
    "print(\"Y:\", list(Y.columns))\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T14:04:00.966353Z",
     "iopub.status.busy": "2021-09-17T14:04:00.965642Z",
     "iopub.status.idle": "2021-09-17T14:04:07.456119Z",
     "shell.execute_reply": "2021-09-17T14:04:07.455264Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cw/dtaijupiter/NoCsBack/dtai/pieterr/Projects/socceraction/.venv/lib/python3.6/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores\n",
      "[16:04:01] WARNING: /tmp/pip-build-aomoa2hx/xgboost/build/temp.linux-x86_64-3.6/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "concedes\n",
      "[16:04:04] WARNING: /tmp/pip-build-aomoa2hx/xgboost/build/temp.linux-x86_64-3.6/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 41.4 s, sys: 207 ms, total: 41.6 s\n",
      "Wall time: 6.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train classifiers F(X) = Y\n",
    "import xgboost\n",
    "\n",
    "Y_hat = pd.DataFrame()\n",
    "models = {}\n",
    "for col in list(Y.columns):\n",
    "    print(col)\n",
    "    model = xgboost.XGBClassifier(n_estimators=50, max_depth=3, n_jobs=-3, verbosity=1)\n",
    "    model.fit(X, Y[col])\n",
    "    models[col] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T14:04:07.463022Z",
     "iopub.status.busy": "2021-09-17T14:04:07.462367Z",
     "iopub.status.idle": "2021-09-17T14:04:09.284641Z",
     "shell.execute_reply": "2021-09-17T14:04:09.284031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Y: scores ###\n",
      "  Brier score: 0.00533 (0.73344)\n",
      "  log loss score: 0.02571 (0.59417)\n",
      "  ROC AUC: 0.93360\n",
      "### Y: concedes ###\n",
      "  Brier score: 0.00100 (0.65121)\n",
      "  log loss score: 0.00551 (0.48045)\n",
      "  ROC AUC: 0.96572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import brier_score_loss, roc_auc_score, log_loss\n",
    "\n",
    "testX, testY = X, Y\n",
    "\n",
    "def evaluate(y, y_hat):\n",
    "    p = sum(y) / len(y)\n",
    "    base = [p] * len(y)\n",
    "    brier = brier_score_loss(y, y_hat)\n",
    "    print(f\"  Brier score: %.5f (%.5f)\" % (brier, brier / brier_score_loss(y, base)))\n",
    "    ll = log_loss(y, y_hat)\n",
    "    print(f\"  log loss score: %.5f (%.5f)\" % (ll, ll / log_loss(y, base)))\n",
    "    print(f\"  ROC AUC: %.5f\" % roc_auc_score(y, y_hat))\n",
    "\n",
    "for col in testY.columns:\n",
    "    Y_hat[col] = [p[1] for p in models[col].predict_proba(testX)]\n",
    "    print(f\"### Y: {col} ###\")\n",
    "    evaluate(testY[col], Y_hat[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T14:04:09.290425Z",
     "iopub.status.busy": "2021-09-17T14:04:09.289756Z",
     "iopub.status.idle": "2021-09-17T14:04:14.474012Z",
     "shell.execute_reply": "2021-09-17T14:04:14.474635Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading actions of each game: 100%|██████████| 64/64 [00:00<00:00, 73.86it/s]\n",
      "Saving predictions per game: 100%|██████████| 64/64 [00:04<00:00, 15.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# get rows with game id per action\n",
    "A = []\n",
    "for game_id in tqdm.tqdm(testgames.game_id, \"Loading actions of each game\"):\n",
    "    Ai = pd.read_hdf(spadl_h5, f\"atomic_actions/game_{game_id}\")\n",
    "    A.append(Ai[[\"game_id\"]])\n",
    "A = pd.concat(A)\n",
    "A = A.reset_index(drop=True)\n",
    "\n",
    "# concatenate action game id rows with predictions and save per game\n",
    "grouped_predictions = pd.concat([A, Y_hat], axis=1).groupby(\"game_id\")\n",
    "for k,df in tqdm.tqdm(grouped_predictions, desc=\"Saving predictions per game\"):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[Y_hat.columns].to_hdf(predictions_h5, f\"game_{int(k)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socceraction",
   "language": "python",
   "name": "socceraction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
